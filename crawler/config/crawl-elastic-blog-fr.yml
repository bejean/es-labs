# This is a sample config file for crawling the parksaustralia.gov.au website writing output to an ES index
#
# The configuration options in this example are not exhaustive. To see all possible configuration options,
# reference the config templates:
# - config/crawler.yml.example
# - config/elasticsearch.yml.example

# Domains allowed for the crawl
domains:
  - url: https://www.elastic.co
    seed_urls:
      - https://www.elastic.co/fr/blog
    sitemap_urls:
      - https://www.elastic.co/sitemap.xml

    crawl_rules:
      - policy: deny       
        type: begins       
        pattern: /fr/blog/author
      - policy: allow       
        type: begins       
        pattern: /fr/blog
      - policy: deny
        type: regex
        pattern: .*

    extraction_rulesets:
      - url_filters:
          - type: begins           
            pattern: /fr/blog 
        rules:
          - action: extract
            field_name: publication_date
            selector: //*[@id="main-content"]/div/section/div[1]/div/div/div/span/time
            join_as: string         
            value: yes             
            source: html           
          - action: extract        
            field_name: author     
            selector: //*[@id="main-content"]/div/section/div[1]/div/div/div/div[2]/div                          
            join_as: array         
            value: yes             
            source: html           
          - action: extract        
            field_name: article     
            selector: //*[@id="main-content"]/div/section/div[3]/div/div/div/div[1]      
            join_as: string         
            value: yes             
            source: html           

# Where to send the results. Possible values are console, file, or elasticsearch
output_sink: file

## Local directory to output crawl results. The defult value is ./crawled_docs
##   This will appear at the top level of your Open Crawler directory if running from source,
##   and under the home/app/ directory inside your container if running via Docker.
output_dir: /output/elastic-blog-fr

# Crawl tuning
max_crawl_depth: 2

# Crawl result field size limits
max_title_size: 500
max_body_size: 5_242_880 # 5 megabytes
max_keywords_size: 512
max_description_size: 512
max_indexed_links_count: 5
max_headings_count: 5
